{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e959b0d-c1c1-40fb-bb9f-288b66d1f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cbd5c4-6202-4e3a-a1b0-7c59144504c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub.file_download\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers.utils.generic\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers.modeling_utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632c8ee2-bcc4-41ef-a187-bd1dfec707ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import coreferee\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c41e95-bc5f-4c8a-8d29-a6c9a08c4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import rebel_spacy\n",
    "from config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "824c5351-e48e-4edf-8214-94a3d135a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, secrets = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6879c974-1634-4cfa-b295-5ad152ea6300",
   "metadata": {},
   "source": [
    "## Declare the text and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730866e6-9a82-4f7e-b190-801149264565",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello! This is a sample text. It contains multiple sentences. How many will spaCy find?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11bcc344-ca10-4664-9c81-50975fba81a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "    spacy_device = 0\n",
    "    torch_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    spacy_device = -1\n",
    "    torch_device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb4d9df-d2f4-4edc-8964-f2e69c403245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rebel_spacy.RebelComponent at 0x736554b4acd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(config.spacy.model_name)\n",
    "nlp.add_pipe(\"rebel\", after=\"senter\", config={\"device\": spacy_device, \"model_name\": config.rebel.model_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61dd3433-10de-46e1-b8f5-a94659ce7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a026e027-2399-4da8-ab07-283056df4205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'a sample text', 'It', 'multiple sentences']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[chunk.text for chunk in doc.noun_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8803027-3b7a-4075-bada-028fd720c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(config.transformer.model_name, legacy=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32b6202b-7433-4c9d-9f78-b65238cb814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModel.from_pretrained(\n",
    "    config.transformer.model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto'\n",
    ")\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91fab366-f7d7-4a83-b6b6-b838549bc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bd3d342-68d3-404d-a5f3-3af3723eda56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,  8479, 29578,   660,   325,   260,  5505,  1880, 29520,   596,\n",
       "          4824,  3567, 17501, 29520,  1058,   931,   477, 15877, 21391,   977,\n",
       "         29584]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3621cfd-a673-4500-be24-3da92e752a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_layer = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1516bfbe-d9e8-47f2-987f-39ac34eea8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded = {k: v.to(torch_device) for k, v in input_encoded.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71c046fb-51db-475c-a4a1-5dd936113e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings = embed_layer(input_encoded[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ff652b8-ca88-41d5-aed6-91a54c3b3ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoded[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5684bd3d-bebb-470b-92b5-ca901b79449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91270616-3c01-413d-803b-ae16bd4056ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = [[token for token in sentence] for sentence in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07f1e504-7793-483d-ad73-288363e97123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello' -  <class 'spacy.tokens.token.Token'>\n",
      "'!' -  <class 'spacy.tokens.token.Token'>\n",
      "'This' -  <class 'spacy.tokens.token.Token'>\n",
      "'is' -  <class 'spacy.tokens.token.Token'>\n",
      "'a' -  <class 'spacy.tokens.token.Token'>\n",
      "'sample' -  <class 'spacy.tokens.token.Token'>\n",
      "'text' -  <class 'spacy.tokens.token.Token'>\n",
      "'.' -  <class 'spacy.tokens.token.Token'>\n",
      "'It' -  <class 'spacy.tokens.token.Token'>\n",
      "'contains' -  <class 'spacy.tokens.token.Token'>\n",
      "'multiple' -  <class 'spacy.tokens.token.Token'>\n",
      "'sentences' -  <class 'spacy.tokens.token.Token'>\n",
      "'.' -  <class 'spacy.tokens.token.Token'>\n",
      "'How' -  <class 'spacy.tokens.token.Token'>\n",
      "'many' -  <class 'spacy.tokens.token.Token'>\n",
      "'will' -  <class 'spacy.tokens.token.Token'>\n",
      "'spaCy' -  <class 'spacy.tokens.token.Token'>\n",
      "'find' -  <class 'spacy.tokens.token.Token'>\n",
      "'?' -  <class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "for sent in tokenized_text:\n",
    "    for word in sent:\n",
    "        print(f\"'{word}' -  {type(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dce4b81f-8a34-4fe4-8b7c-e7b979a41a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[token for sent in doc.sents for token in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b128d717-556a-4cc8-89fb-dbfc630ad363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Hello, !],\n",
       " [This, is, a, sample, text, .],\n",
       " [It, contains, multiple, sentences, .],\n",
       " [How, many, will, spaCy, find, ?]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[token for token in sent] for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0270dc8-3048-4f8e-9da8-2da41f34d636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hello', 'INTJ'), ('!', 'PUNCT'), ('This', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('sample', 'NOUN'), ('text', 'NOUN'), ('.', 'PUNCT'), ('It', 'PRON'), ('contains', 'VERB'), ('multiple', 'ADJ'), ('sentences', 'NOUN'), ('.', 'PUNCT'), ('How', 'SCONJ'), ('many', 'ADJ'), ('will', 'AUX'), ('spaCy', 'VERB'), ('find', 'VERB'), ('?', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddbf9f25-cc1b-464c-90a1-025d873b32f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hello', 'punct', '!'), ('is', 'nsubj', 'This'), ('text', 'det', 'a'), ('text', 'compound', 'sample'), ('is', 'attr', 'text'), ('is', 'punct', '.'), ('contains', 'nsubj', 'It'), ('sentences', 'amod', 'multiple'), ('contains', 'dobj', 'sentences'), ('contains', 'punct', '.'), ('many', 'advmod', 'How'), ('find', 'nsubj', 'many'), ('find', 'aux', 'will'), ('find', 'nsubj', 'spaCy'), ('find', 'punct', '?')]\n",
      "\n",
      "Named Entities:\n"
     ]
    }
   ],
   "source": [
    "relationships = []\n",
    "    \n",
    "# Iterate through each token in the document\n",
    "for token in doc:\n",
    "    # Check if the token has a head (to avoid root)\n",
    "    if token.dep_ != \"ROOT\":\n",
    "        # Create a tuple of (governor, relationship, dependent)\n",
    "        relationship = (token.head.text, token.dep_, token.text)\n",
    "        relationships.append(relationship)\n",
    "\n",
    "print(relationships)\n",
    "\n",
    "\n",
    "def analyze_semantic_relationships(text):\n",
    "    # Load the English language model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Initialize dictionaries to store nodes and relationships\n",
    "    nodes = defaultdict(set)\n",
    "    relationships = []\n",
    "    \n",
    "    # Iterate through each token in the document\n",
    "    for token in doc:\n",
    "        # Check if the token has a head (to avoid root)\n",
    "        if token.dep_ != \"ROOT\":\n",
    "            # Add governor and dependent to nodes\n",
    "            nodes[token.head.pos_].add(token.head.text)\n",
    "            nodes[token.pos_].add(token.text)\n",
    "            \n",
    "            # Create a tuple of (governor, relationship, dependent)\n",
    "            relationship = (token.head.text, token.dep_, token.text)\n",
    "            relationships.append(relationship)\n",
    "    \n",
    "    return nodes, relationships\n",
    "\n",
    "\n",
    "\n",
    "# Named Entity Recognition\n",
    "def analyze_named_entities(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    print(\"\\nNamed Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"CREATE (:{ent.label_} {{name: '{ent.text}'}})\")\n",
    "\n",
    "# Example usage for Named Entity Recognition\n",
    "analyze_named_entities(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49772d6-7b67-4401-bacc-01983e03af44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
