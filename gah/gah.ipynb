{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0a5695-a57a-44aa-8d99-201e7e6d1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers.utils\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"thinc.shims\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"spacy_transformers.layers\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"spacy_transformers.layers\")\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"spacy.util\")\n",
    "\n",
    "import torch\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from spacy import displacy\n",
    "from functools import reduce\n",
    "import utils\n",
    "import rebel_spacy\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "from config import load_config\n",
    "from graphs import (\n",
    "    explode_columns,\n",
    "    run_query,\n",
    "    get_all_relationships,\n",
    "    get_all_nodes,\n",
    "    cleanup_database,\n",
    "    create_relationship,\n",
    "    create_node,\n",
    ")\n",
    "\n",
    "#from spacy_custom import get_relations\n",
    "from spacy.tokens import Doc\n",
    "from wasabi import msg\n",
    "\n",
    "from coref import resolve_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ad8e21-ac2f-4236-9781-fa3b30bbe1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch_device = \"gpu\" \n",
    "    rebel_device = 0\n",
    "else:\n",
    "    torch_device =\"cpu\"\n",
    "    rebel_device = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7499677f-6f38-4292-8ff8-25be9d96ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, secrets = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3366a82-4abd-426e-94ec-5d30a1ab2a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset and retrieve just a sample in `ds`\n",
    "roc18_ds = datasets.load_dataset(\"igormorgado/ROCStories2018\")\n",
    "ds = roc18_ds['train'].select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9b020f3-8190-406f-ade9-1fc01ae299a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "#nlp.analyze_pipes(pretty=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1e2036-c6e2-4a31-9e5e-1f1cf6a2d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp_coref = spacy.load(\"en_coreference_web_trf\")\n",
    "# use replace_listeners for the coref components\n",
    "#nlp_coref.replace_listeners(\"transformer\", \"coref\", [\"model.tok2vec\"])\n",
    "#nlp_coref.replace_listeners(\"transformer\", \"span_resolver\", [\"model.tok2vec\"])\n",
    "#nlp.add_pipe(\"merge_entities\")\n",
    "#nlp.add_pipe(\"coref\", source=nlp_coref)\n",
    "#nlp.add_pipe(\"span_resolver\", source=nlp_coref)\n",
    "#nlp_coref.analyze_pipes(pretty=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea39b98-014c-4161-95e3-7cbf68244e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_nlp = nlp(text)\n",
    "#doc_coref = nlp_coref(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cac82f5b-e875-445e-8802-10f79cd19e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_json(token, sentence_id):\n",
    "    token_dict = {\n",
    "        \"id\": f\"{sentence_id}_{token.i}\",\n",
    "        \"sentence_id\": sentence_id,\n",
    "        \"text\": token.text,\n",
    "        \"lemma\": token.lemma_,\n",
    "        \"pos\": token.pos_,\n",
    "        \"tag\": token.tag_,\n",
    "        \"dep\": token.dep_,\n",
    "        \"is_alpha\": token.is_alpha,\n",
    "        \"is_stop\": token.is_stop,\n",
    "        \"is_sent_start\": token.is_sent_start,\n",
    "        \"head\": f\"{sentence_id}_{token.head.i}\",\n",
    "    }\n",
    "    return token_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83eabd8a-40f9-4b5e-a81d-56e7dd7067f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using rebel for now to extract Relations.\n",
    "# spacy_lm = 'en_core_web_sm'\n",
    "# relext_pipeline = spacy.load(spacy_lm, disable=['ner', 'lemmatizer', 'attribute_rules', 'tagger'])\n",
    "\n",
    "# rebel_config_params = {\n",
    "#     'device': rebel_device,\n",
    "#     'model_name': 'Babelscape/rebel-large'\n",
    "# }\n",
    "# rebel_comp = relext_pipeline.add_pipe(\"rebel\", config=rebel_config_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684f3139-98f1-4abb-bf74-2ae6f8c48a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc[doc.ents[0].start:doc.ents[0].end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "262f4fe6-8d7f-49b9-a626-95f88e953286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_token_query() -> str:\n",
    "    query = \"\"\"\n",
    "        CREATE (t:Token {\n",
    "            id: $id,\n",
    "            sentence_id: $sentence_id,\n",
    "            text: $text,\n",
    "            pos: $pos,\n",
    "            tag: $tag,\n",
    "            lemma: $lemma,\n",
    "            is_alpha: $is_alpha,\n",
    "            is_stop: $is_stop,\n",
    "            is_sent_start: $is_sent_start\n",
    "        })\n",
    "        RETURN t\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "def build_dependency_query() -> str:\n",
    "    query = \"\"\"\n",
    "        MATCH (t1:Token {id: $id}), (t2:Token {id: $head})\n",
    "        CREATE (t1)-[:DEPENDS_ON {type: $dep}]->(t2)\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "def build_sentence_query() -> str:\n",
    "    query = \"\"\"\n",
    "        MATCH (r1:Token {id: $id}), (r2:Token {id: $next})\n",
    "        CREATE (r1)-[:NEXT_SENTENCE]->(r2)\n",
    "    \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "861cb64d-9c37-4c7b-86e1-0a3d9f89ca4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David 1\n",
      "noticed 1\n",
      "he 4\n",
      "had 4\n",
      "put 1\n",
      "on 4\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:6]:\n",
    "    print(token, token.head.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9616ba6-a720-4680-9da2-621d3b67b4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency graph created in Neo4j with 5 sentences linked.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(config.neo4j.uri, auth=(config.neo4j.username, secrets.neo4j_password))\n",
    "with driver.session() as session:\n",
    "    # Clear existing graph\n",
    "    session.execute_write(cleanup_database)\n",
    "\n",
    "    roots = []\n",
    "    sentence_id = 0\n",
    "\n",
    "    for sentence_id, sent in enumerate(doc.sents):\n",
    "        root = None\n",
    "     \n",
    "        # Create nodes for each token in the sentence\n",
    "        for token in sent:\n",
    "            query = build_token_query()\n",
    "            data = token_to_json(token, sentence_id)\n",
    "            node = session.execute_write(run_query, query, data)\n",
    "            \n",
    "            if token.dep_ == \"ROOT\":\n",
    "                roots.append(node)\n",
    "                   \n",
    "        # Create relationships based on dependencies within the sentence\n",
    "        for token in sent:\n",
    "            if token.head.i != token.i:  # Exclude root\n",
    "                query = build_dependency_query()\n",
    "                data = token_to_json(token, sentence_id)\n",
    "                session.execute_write(run_query, query, data)\n",
    "    \n",
    "    # Create relationships between sentence roots\n",
    "    roots_df = pd.concat(roots, ignore_index=True)\n",
    "    root_ids = list(roots_df['t'].apply(lambda x: x.get('id')))\n",
    "    for id_, next_ in zip(root_ids[:-1], root_ids[1:]):\n",
    "        query = build_sentence_query()\n",
    "        data = {\"id\": id_, \"next\": next_}\n",
    "        session.execute_write(run_query, query, data)\n",
    "\n",
    "    driver.close()\n",
    "    print(f\"Dependency graph created in Neo4j with {len(root_ids)} sentences linked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "22be48b2-f5fb-4419-81d5-3e22bb05a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_ids = list(roots_df['t'].apply(lambda x: x.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50e872e4-faf7-4698-835a-da719e51815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0_1', '1_12'), ('1_12', '2_19'), ('2_19', '3_33'), ('3_33', '4_41')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(root_ids[:-1], root_ids[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "692fb8c4-9905-467a-919c-9701925d7c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0_1'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_roots[0]['t'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f631769f-ec96-4def-927c-67d1dc4a1368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1_14'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_roots[1]['t'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bc052fc-3716-44e5-9dae-186bf8daaceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (is_sent_start, sentence_id, pos, is_alpha, le...\n",
       "1    (is_sent_start, sentence_id, pos, is_alpha, le...\n",
       "2    (is_sent_start, sentence_id, pos, is_alpha, le...\n",
       "3    (is_sent_start, sentence_id, pos, is_alpha, le...\n",
       "Name: t, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(sentence_roots, ignore_index=True)['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28b07fb-9af3-4919-941a-eb9f14f0602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = utils.rocstory(ds[0])\n",
    "doc = nlp(text)\n",
    "\n",
    "#create_dependency_graph(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cfc948-67fa-424c-890e-6d792b4d1665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a037157-7b7d-42e0-a9de-11f43238b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(config.neo4j.uri, auth=(config.neo4j.username, secrets.neo4j_password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d305cbe0-71e9-455b-bb76-971db54aef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = driver.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5858c6-e190-4938-9fbb-1da334e1dbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
